{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib, cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import ImageFont, ImageDraw, Image\n",
    "import tensorflow.keras \n",
    "from tensorflow.keras import backend as K\n",
    "import glob\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "sp = dlib.shape_predictor('models/shape_predictor_68_face_landmarks.dat')\n",
    "facerec = dlib.face_recognition_model_v1('models/dlib_face_recognition_resnet_model_v1.dat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saved Face Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_faces(img):\n",
    "    dets = detector(img, 1)\n",
    "\n",
    "    if len(dets) == 0:\n",
    "        return np.empty(0), np.empty(0), np.empty(0)\n",
    "    \n",
    "    rects, shapes = [], []\n",
    "    shapes_np = np.zeros((len(dets), 68, 2), dtype=np.int)\n",
    "    for k, d in enumerate(dets):\n",
    "        rect = ((d.left(), d.top()), (d.right(), d.bottom()))\n",
    "        rects.append(rect)\n",
    "\n",
    "        shape = sp(img, d)\n",
    "        \n",
    "        # convert dlib shape to numpy array\n",
    "        for i in range(0, 68):\n",
    "            shapes_np[k][i] = (shape.part(i).x, shape.part(i).y)\n",
    "\n",
    "        shapes.append(shape)\n",
    "        \n",
    "    return rects, shapes, shapes_np\n",
    "\n",
    "\n",
    "def encode_faces(img, shapes):\n",
    "    face_descriptors = []\n",
    "    for shape in shapes:\n",
    "        face_descriptor = facerec.compute_face_descriptor(img, shape)\n",
    "        face_descriptors.append(np.array(face_descriptor))\n",
    "\n",
    "    return np.array(face_descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "259\n"
     ]
    }
   ],
   "source": [
    "label_name = []\n",
    "label_class = {}\n",
    "img_paths = glob.glob(\"kpop_img/*\")\n",
    "\n",
    "for path in img_paths:\n",
    "    name = path.split(\".\")[0][9:]\n",
    "    label_name.append(name)\n",
    "    label_class[name] = path\n",
    "\n",
    "#print(label_name)\n",
    "print(len(label_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_16640\\939484637.py:8: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  shapes_np = np.zeros((len(dets), 68, 2), dtype=np.int)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\lib\\npyio.py:501: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n"
     ]
    }
   ],
   "source": [
    "descs = []\n",
    "\n",
    "for name, label_path in label_class.items():\n",
    "    img = cv2.imread(label_path)\n",
    "#    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # BGR -> RGB\n",
    "    _, img_shapes, _ = find_faces(img)\n",
    "    descs.append([name, encode_faces(img, img_shapes)[0]])\n",
    "\n",
    "np.save('descs.npy', descs)\n",
    "#print(descs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Face Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "descs = np.load('descs.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 닮은 연예인 찾기(저장된 사진으로 찾기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(img, comment, x, y, h, size):\n",
    "    img = Image.fromarray(img)\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    draw.text((x+5,y+h), comment, font=ImageFont.truetype(\"./batang.ttc\", size), fill=(40,180,120))\n",
    "    # \n",
    "    return np.array(img)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = cv2.imread('test_img/taeyeon.jpg')\n",
    "# #img = cv2.imread('test_img/chen.jpg')\n",
    "# #img = cv2.imread('test_img/jinho.jpg')\n",
    "\n",
    "# img = cv2.flip(img, 1) # 좌우 대칭\n",
    "# rects, shapes, _ = find_faces(img) # 얼굴 찾기\n",
    "# descriptors = encode_faces(img, shapes) # 인코딩\n",
    "\n",
    "# if(len(descriptors) == 0):\n",
    "#     print(\"얼굴 인식이 안되었네요ㅜㅜ \\n다시 찍어주세요!\")\n",
    "# elif(len(descriptors) > 1):\n",
    "#     print(\"여러 명이 인식이 되었네요ㅜㅜ \\n혼자 다시 찍어주세요!\")\n",
    "# else:\n",
    "#     desc = descriptors[0]\n",
    "#     x = rects[0][0][0] # 얼굴 X 좌표\n",
    "#     y = rects[0][0][1] # 얼굴 Y 좌표\n",
    "#     w = rects[0][1][1]-rects[0][0][1] # 얼굴 너비 \n",
    "#     h = rects[0][1][0]-rects[0][0][0] # 얼굴 높이        \n",
    "\n",
    "#     descs1 = sorted(descs, key=lambda x: np.linalg.norm([desc] - x[1]))\n",
    "#     dist = np.linalg.norm([desc] - descs1[0][1], axis=1)\n",
    "#     if dist < 0.5:\n",
    "#         name = descs1[0][0]\n",
    "#         comment = \"{0}을 닮으셨네요. 올~~\".format(name) \n",
    "#         img = cv2.imread(label_class[name])\n",
    "# #             img = cv2.resize(img, dsize=(780, 520))\n",
    "#         result = draw(img, comment, x-10, y, h, 36)\n",
    "#     else:\n",
    "#         comment = \"닮은 연예인이 없네요\\nㅜㅜ 성형하고 오세요!\\n\"\n",
    "#         img = cv2.imread(\"test_img/ojingeo.jpg\")\n",
    "#         result = draw(img, comment, 50, 10, h, 24)\n",
    "\n",
    "#     print(\"거리: %.3f\" % dist[0])\n",
    "#     print(comment)\n",
    "# #    cv2.imshow(name, result)\n",
    "#     result = cv2.cvtColor(result, cv2.COLOR_BGR2RGB) # BGR -> RGB\n",
    "#     plt.imshow(result)\n",
    "\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 닮은 연예인 찾기(실시간으로 찍어서 찾기)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 버전 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "얼굴 인식이 안되었네요ㅜㅜ \n",
      "다시 찍어주세요!\n"
     ]
    }
   ],
   "source": [
    "user_name = input(\"너의 이름은? \") # 사용자 이름 입력\n",
    "\n",
    "cap = cv2.VideoCapture(0) # 노트북 웹캠을 카메라로 사용\n",
    "cap.set(3,640) # 너비\n",
    "cap.set(4,480) # 높이\n",
    "\n",
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.flip(frame, 1) # 좌우 대칭\n",
    "    \n",
    "    cv2.imshow('frame', frame)\n",
    "    \n",
    "    k = cv2.waitKey(30) & 0xff \n",
    "    if k == 49: # 1 키를 누르면 사진 찍음.\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "        rects, shapes, _ = find_faces(frame) # 얼굴 찾기\n",
    "        descriptors = encode_faces(frame, shapes) # 인코딩\n",
    "\n",
    "        if(len(descriptors) == 0):\n",
    "            print(\"얼굴 인식이 안되었네요ㅜㅜ \\n다시 찍어주세요!\")\n",
    "        elif(len(descriptors) > 1):\n",
    "            print(\"여러 명이 인식이 되었네요ㅜㅜ \\n혼자 다시 찍어주세요!\")\n",
    "        else:\n",
    "            desc = descriptors[0]\n",
    "            x = rects[0][0][0] # 얼굴 X 좌표\n",
    "            y = rects[0][0][1] # 얼굴 Y 좌표\n",
    "            w = rects[0][1][1]-rects[0][0][1] # 얼굴 너비 \n",
    "            h = rects[0][1][0]-rects[0][0][0] # 얼굴 높이        \n",
    "\n",
    "            descs1 = sorted(descs, key=lambda x: np.linalg.norm([desc] - x[1]))\n",
    "            dist = np.linalg.norm([desc] - descs1[0][1], axis=1)\n",
    "            if dist < 0.4:\n",
    "                name = descs1[0][0]\n",
    "                comment = \"{0}을 닮으셨네요.\".format(name) \n",
    "                img = cv2.imread(label_class[name])\n",
    "#                 img = cv2.resize(img, dsize=(780, 520))\n",
    "                result = draw(img, comment, x-10, y, h, 36)\n",
    "            else:\n",
    "                comment = \"닮은 연예인이 없네요\\nㅜㅜ \\n\"\n",
    "                img = cv2.imread(\"test_img/ojingeo.jpg\")\n",
    "                result = draw(img, comment, 50, 10, h, 24)\n",
    "            \n",
    "            print(\"거리: %.3f\" % dist[0])\n",
    "            print(comment)\n",
    "            cv2.imshow(name, result)\n",
    "#             result = cv2.cvtColor(result, cv2.COLOR_BGR2RGB) # BGR -> RGB\n",
    "#             plt.imshow(result)\n",
    "\n",
    "        break\n",
    "    \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 버전 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_name = input(\"너의 이름은? \") # 사용자 이름 입력\n",
    "\n",
    "# cap = cv2.VideoCapture(0) # 노트북 웹캠을 카메라로 사용\n",
    "# cap.set(3,640) # 너비\n",
    "# cap.set(4,480) # 높이\n",
    "\n",
    "# while(True):\n",
    "#     ret, frame = cap.read()\n",
    "#     frame = cv2.flip(frame, 1) # 좌우 대칭\n",
    "    \n",
    "#     cv2.imshow('frame', frame)\n",
    "    \n",
    "#     k = cv2.waitKey(30) & 0xff \n",
    "#     if k == 49: # 1 키를 누르면 사진 찍음.\n",
    "#         cap.release()\n",
    "#         cv2.destroyAllWindows()\n",
    "        \n",
    "#         rects, shapes, _ = find_faces(frame) # 얼굴 찾기\n",
    "#         descriptors = encode_faces(frame, shapes) # 인코딩\n",
    "\n",
    "#         if(len(descriptors) == 0):\n",
    "#             print(\"얼굴 인식이 안되었네요ㅜㅜ \\n다시 찍어주세요!\")\n",
    "#         elif(len(descriptors) > 1):\n",
    "#             print(\"여러 명이 인식이 되었네요ㅜㅜ \\n혼자 다시 찍어주세요!\")\n",
    "#         else:\n",
    "#             desc = descriptors[0]\n",
    "#             x = rects[0][0][0] # 얼굴 X 좌표\n",
    "#             y = rects[0][0][1] # 얼굴 Y 좌표\n",
    "#             w = rects[0][1][1]-rects[0][0][1] # 얼굴 너비 \n",
    "#             h = rects[0][1][0]-rects[0][0][0] # 얼굴 높이        \n",
    "\n",
    "#             descs1 = sorted(descs, key=lambda x: np.linalg.norm([desc] - x[1]))\n",
    "#             dist = np.linalg.norm([desc] - descs1[0][1], axis=1)\n",
    "#             if dist < 0.45:\n",
    "#                 name = descs1[0][0]\n",
    "#                 comment = \"{0}을 닮으셨네요. 올~~\".format(name) \n",
    "#                 img = cv2.imread(label_class[name])\n",
    "# #                 img = cv2.resize(img, dsize=(780, 520))\n",
    "#                 result = draw(img, comment, x-10, y, h, 36)\n",
    "#             else:\n",
    "#                 print(dist)\n",
    "#                 comment = \"{0}님은 닮은 연예인이 없네요\\nㅜㅜ 성형하고 오세요!\\n\".format(user_name)\n",
    "#                 img = cv2.imread(\"test_img/ojingeo1.png\")\n",
    "#                 img = cv2.resize(img, dsize=(w, h+30)) \n",
    "#                 frame[y-30:y+h, x:x+w] = img \n",
    "#                 result = draw(frame, comment, 50, 10, h, 24)\n",
    "\n",
    "#             print(comment)\n",
    "# #             cv2.imshow(name, result)\n",
    "#             result = cv2.cvtColor(result, cv2.COLOR_BGR2RGB) # BGR -> RGB\n",
    "#             plt.imshow(result)\n",
    "\n",
    "#         break\n",
    "    \n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "afb734500600fd355917ca529030176ea0ca205570884b88f2f6f7d791fd3fbe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
